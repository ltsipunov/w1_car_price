{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849a89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import timeit as ti\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "np.random.seed(4999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e30b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63dcbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from category_encoders.target_encoder import TargetEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afed79e",
   "metadata": {},
   "source": [
    "####  Load and purge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42db2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self,path = None, dsets=None,teacher=None):\n",
    "        if path is not None:\n",
    "            self.fe = pd.read_csv(path)\n",
    "            if 'sellingprice' in self.fe.columns:\n",
    "                self.ta = self.fe['sellingprice']\n",
    "                self.fe = self.fe.drop(['sellingprice'],axis=1) \n",
    "            self.vin = self.fe['vin']\n",
    "            self.fe = self.fe.drop(['vin'],axis=1) \n",
    "            self.fe = self.fe.rename(columns={'year':'prod_year'})\n",
    "        elif dsets is not None:\n",
    "            self.fe = dsets[0].copy()\n",
    "            self.ta = dsets[1].copy()\n",
    "        else:\n",
    "            raise 'Wrong DataSet constructor , all values are None'\n",
    "        self.teacher = teacher    \n",
    "\n",
    "\n",
    "        self.price_cols = ['sellingprice','pr','pe']\n",
    "        self.make_cols = ['make','model','trim']\n",
    "        self.wear_cols = ['prod_year','condition','odometer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9069508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def fillna(self):\n",
    "    self.fe[['make','model','trim']] = self.fe[['make','model','trim']].fillna('UNKNOWN')\n",
    "    self.fe[['color','interior']] = self.fe[['color','interior']].fillna('â€”')\n",
    "    self.fe['transmission'] = self.fe['transmission'].fillna('automatic')\n",
    "    cond_mean = self.fe.groupby('prod_year').condition.mean()\n",
    "    idx_na= self.fe.condition.isna()\n",
    "    self.fe.loc[idx_na,'condition'] = self.fe[idx_na].prod_year.apply(lambda s: cond_mean[s])\n",
    "    run_mean = self.fe.groupby('prod_year').odometer.mean()\n",
    "    idx_na=self.fe.odometer.isna() \n",
    "    self.fe.loc[idx_na,'odometer'] = self.fe[idx_na].prod_year.apply(lambda s: run_mean[s])\n",
    "    return(self)\n",
    "    \n",
    "DataSet.fillna = fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c206f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(self,rounding):\n",
    "    start = ti.default_timer()\n",
    "    cols_to_upper= ['make','model','trim','body']\n",
    "    cols_dt = ['year','month','day','hour','minute','second','weekday','yearday','dl']\n",
    "    cols_abbr = ['trim','seller']\n",
    "    cols_trash = ['saledate','trim','abbr_seller','seller','second','yearday','dl']\n",
    "    def transform_row(r,cols_to_upper,cols_dt,cols_abbr):\n",
    "        def abbr(s,prefix_size=5 ):\n",
    "            s = s.strip().upper()\n",
    "            if len(s) <= prefix_size:\n",
    "                return(s)\n",
    "            s = s[:prefix_size].replace(' ','-')+s[prefix_size:]\n",
    "            i = s.find(' ')\n",
    "            if i > 0:\n",
    "                s = s[:i]        \n",
    "            return(s)\n",
    "\n",
    "        t =  dt.datetime.strptime(r['saledate'].split('GMT')[0]  ,\"%a %b %d %Y %H:%M:%S \").timetuple()\n",
    "        dc = dict(zip(cols_dt ,t))\n",
    "        for col in cols_abbr:\n",
    "            dc['abbr_'+col] = abbr(r[col])\n",
    "\n",
    "        for col in cols_to_upper:\n",
    "            dc[col] = str(r[col]).upper()\n",
    "        dc['odometer']= round(r['odometer']/rounding['odometer']) \n",
    "        dc['condition']= round(r['condition'],rounding['condition']) \n",
    "        return dc\n",
    "\n",
    "    transformed = self.fe.apply(transform_row, axis=1,result_type='expand',\n",
    "                                         cols_to_upper=cols_to_upper,cols_dt=cols_dt,cols_abbr=cols_abbr)\n",
    "    self.fe[transformed.columns] = transformed   \n",
    "    \n",
    "    self.fe = self.fe.drop(cols_trash ,axis=1)\n",
    "#    print(f\"normalize: {ti.default_timer()-start} s \" )\n",
    "    return self\n",
    "\n",
    "DataSet.normalize = normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c5d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_(self,rate):\n",
    "    fe0,fe1,ta0,ta1 = train_test_split(self.fe,self.ta,test_size=rate )\n",
    "    return DataSet(dsets = [fe0,ta0]),DataSet( dsets = [fe1,ta1])\n",
    "DataSet.split = split_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28866de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew(self,threshold,mult):\n",
    "    ta0 = self.ta[self.ta>threshold]\n",
    "    ta1 = self.ta[self.ta<threshold]\n",
    "    fe0 = self.fe[self.ta>threshold]\n",
    "    fe1 = self.fe[self.ta<threshold]\n",
    "    if mult >=1:\n",
    "         ta_new = pd.concat( [ta0]+mult*[ta1] ,axis=0).copy()\n",
    "         fe_new = pd.concat( [fe0]+mult*[fe1] ,axis=0).copy()\n",
    "    else:\n",
    "        idx = ta0.sample(frac=mult, replace=True).index\n",
    "        ta_new = pd.concat( [ta0[idx]]+[ta1] ,axis=0).copy()\n",
    "        fe_new = pd.concat( [fe0.loc[idx]]+[fe1] ,axis=0).copy()        \n",
    "    self.fe,self.ta =  shuffle(fe_new,ta_new)\n",
    "    return self\n",
    "\n",
    "DataSet.skew = skew\n",
    "# fe5,ta5 = swing_price(fe_tr,ta_tr,5000,.1)\n",
    "# print(fe5.shape,ta5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167d8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(self):\n",
    "    start= ti.default_timer()\n",
    "    if self.teacher is None:\n",
    "#        self.enc= OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "        self.enc= TargetEncoder(handle_unknown='value')\n",
    "        self.enc.fit(self.fe,self.ta)\n",
    "    else:\n",
    "        self.enc= self.teacher.enc\n",
    "    self.fe = pd.DataFrame( self.enc.transform(self.fe),columns = self.enc.get_feature_names_out() )\n",
    "\n",
    "    print(f\"encode: {ti.default_timer()-start} s \" )\n",
    "    return self\n",
    "\n",
    "DataSet.encode = encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36624f",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec3d7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounding,\t threshold,\t mult, \t score, \t time \t start\n",
      "encode: 8.800801000000007 s \n",
      "encode: 0.897882899999999 s \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataSet' object has no attribute 'ta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:19\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataSet' object has no attribute 'ta'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#ds = DataSet(path='datasets/train.csv').fillna().normalize().encode().skew(threshold=3000,mult = 5)\n",
    "#dst = DataSet(path='datasets/test.csv',teacher=ds).fillna().normalize().encode()\n",
    "print(f\"rounding,\\t threshold,\\t mult, \\t score, \\t time \\t start\")\n",
    "for rounding in [3000]:\n",
    "    for threshold in [4000]:\n",
    "        for mult in [4]:\n",
    "            start = ti.default_timer()\n",
    "            norm_dc = {'condition':1,'odometer':rounding}\n",
    "            ds=DataSet('datasets/train.csv').fillna().normalize(norm_dc).encode().skew(threshold=threshold,mult=mult)\n",
    "            dst=DataSet(path='datasets/test.csv',teacher=ds).fillna().normalize(norm_dc).encode()\n",
    "            md = RandomForestRegressor(criterion='poisson',\n",
    " #                                  max_depth=200, n_estimators=500,\n",
    "                                   max_depth=50, n_estimators=200,                                       \n",
    "                                   min_samples_split=2, min_samples_leaf=2, max_features=16,\n",
    "                                   warm_start=True)\n",
    "            md.fit(ds.fe,ds.ta)\n",
    "            prt = md.predict(dst.fe)\n",
    "            stop = ti.default_timer()\n",
    "            print(f\"{rounding},\\t{threshold},\\t{mult},\\t{mape(prt,dst.ta)},\\t {round(stop-start)},\\t {start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f6a5c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataSet' object has no attribute 'ta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrounding\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmape(prt,dst\u001b[38;5;241m.\u001b[39mta)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(stop\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataSet' object has no attribute 'ta'"
     ]
    }
   ],
   "source": [
    "print(f\"{rounding},\\t{threshold},\\t{mult},\\t{mape(prt,dst.ta)},\\t {round(stop-start)},\\t {start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.fe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst.fe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70350651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ds.fe.columns:\n",
    "    if sum(ds.fe[c].isna())>0:\n",
    "        print(c, sum(ds.fe[c].isna()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3993f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prt = pd.Series( md.predict(dst.fe),index=dst.fe.index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bf6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(dst.ta,prt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8d6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09112923",
   "metadata": {},
   "outputs": [],
   "source": [
    "prv = pd.DataFrame({'vin': dst.vin,'sellingprice':prt} )\n",
    "prv.to_csv('datasets/result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38db255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'real':dst.ta,'predict':prt}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5786c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in dst.fe.columns:\n",
    "    print( c, sum( dst.fe[c]==-1 ) )\n",
    "dst.fe.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f742b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad75253",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ds.columns:\n",
    "    print(f\"{c} : ----- { ds[c].value_counts().size } ============> NaNs: {sum(ds[c].isna()) }----\")\n",
    "    print(dict( ds[c].value_counts().head(10)) )\n",
    "    print(dict( ds[c].value_counts().tail()) )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e831cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347763d",
   "metadata": {},
   "source": [
    "#### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cfe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_vin = ds.vin\n",
    "ds_ta = ds.sellingprice\n",
    "trash_cols = ['saledate','trim','abbr_seller','seller','second','yearday','dl']+['year','hour','minute','weekday']\n",
    "ds_fe = ds.drop(['vin','sellingprice']+trash_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576dfe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc= OrdinalEncoder()\n",
    "ds_fe = pd.DataFrame( enc.fit_transform(ds_fe),columns = enc.get_feature_names_out() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4191c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_tr,fe_va,ta_tr,ta_va = train_test_split(ds_fe,ds_ta,test_size = .25)\n",
    "print( fe_tr.shape,fe_va.shape,ta_tr.shape,ta_va.shape)\n",
    "fe_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211abb0f",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c6b55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for n_est in [200]:\n",
    "    for mss in [2]:\n",
    "        for msl in [2]:\n",
    "            for mf in [24]:\n",
    "                for cri in ['poisson']:  \n",
    "#            min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0\n",
    "                    start = ti.default_timer()  \n",
    "                    md = RandomForestRegressor(criterion=cri,max_depth=100, n_estimators=n_est,\n",
    "       #                  random_state = 5555,                      \n",
    "                         min_samples_split=mss, min_samples_leaf=msl, max_features=mf,\n",
    "                         warm_start=True)\n",
    "                    md.fit(fe_tr,ta_tr)\n",
    "                    prt = pd.Series( md.predict(fe_va),index=fe_va.index )\n",
    "                    print(f\"est:{n_est} mss:{mss} msl:{msl} mf:{mf} cri:{cri}=> {mape(ta_va,prt)} | {ti.default_timer()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9250c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = prt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a9521",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mape(ta_va,pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361be815",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6863a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# md = DecisionTreeRegressor(max_depth=333)\n",
    "# md.fit(fe_tr,ta_tr)\n",
    "# prt = pd.Series( md.predict(fe_va),index=fe_va.index )\n",
    "# mape(ta_va,prt)               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673ef69",
   "metadata": {},
   "source": [
    "#### Final fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = abs(pr-ta_va)/(pr+ta_va)\n",
    "pe.hist(figsize=(20,6),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61759297",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['pr'] = pr\n",
    "ds['pe'] = pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb98ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( ds.sellingprice[ds.pe < 10_000_000 ].shape,pr.shape,ta_va.shape,(pr-ta_va).shape )\n",
    "pr.head().index,ta_va.head().index,fe_va.head().index,(pr - ta_va).head().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in [1000,2000,3500,5000]:\n",
    "    print(f\" {th}:\\t { mape(pr[pr>th],ta_va[pr>th])} \\t {pr[pr<th].shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe5f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mape(ta_va[ds.pe<.25],pr[ds.pe<.25]),mape(ta_va[ds.pe<.5],pr[ds.pe<.5]),mape(ta_va[ds.pe<.75],pr[ds.pe<.75]))\n",
    "#diffs_50_plus = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def swing_price(fe,ta,th,k):\n",
    "    ta0 = ta[ta>th]\n",
    "    ta1 = ta[ta<th]\n",
    "    fe0 = fe[ta>th]\n",
    "    fe1 = fe[ta<th]\n",
    "    if k >=1:\n",
    "        ta_new = pd.concat( [ta0]+k*[ta1] ,axis=0).copy()\n",
    "        fe_new = pd.concat( [fe0]+k*[fe1] ,axis=0).copy()\n",
    "    else:\n",
    "        idx = ta0.sample(frac=k).index\n",
    "        ta_new = pd.concat( [ta0[idx]]+[ta1] ,axis=0).copy()\n",
    "        fe_new = pd.concat( [fe0.loc[idx]]+[fe1] ,axis=0).copy()        \n",
    "    return shuffle(fe_new,ta_new)\n",
    "fe5,ta5 = swing_price(fe_tr,ta_tr,5000,.1)\n",
    "print(fe5.shape,ta5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aca19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for th in (3000,6000):\n",
    "    for mlt in (5,10):\n",
    "        start = ti.default_timer()\n",
    "        fe,ta = swing_price(fe_tr,ta_tr,th,mlt)\n",
    "        md = RandomForestRegressor(criterion='poisson',max_depth=100, n_estimators=200,\n",
    "                          random_state = 5555,                      \n",
    "             min_samples_split=2, min_samples_leaf=2, max_features=24,\n",
    "             warm_start=True)\n",
    "        md.fit(fe,ta)\n",
    "        prt = pd.Series( md.predict(fe_va),index=fe_va.index )\n",
    "        print(f\" {th} {mlt} --> {mape(ta_va,prt)} | {ti.default_timer()-start} {ti.default_timer()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( ds.sellingprice.mean(),pr.mean(),rel_diffs.sellingprice.mean(),rel_diffs.pr.mean() )\n",
    "rel_diffs[price_cols+make_cols+wear_cols+['seller']+['abbr_power']+['q25']+['state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame( {\n",
    "'d50': diffs_50.q25.value_counts().head(30),\n",
    "'d66': diffs_66.q25.value_counts().head(30),\n",
    "'ds': ds.q75.value_counts().head(30)\n",
    "}    ).sort_values(by = 'd50',ascending=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bb20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13626ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print( rel_diffs.seller.value_counts() )\n",
    "#ds.seller.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c21616",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd = ds.pivot_table(\n",
    "    index='seller',values=['sellingprice','condition'],aggfunc=['mean','count']\n",
    ")\n",
    "cnd[ cnd[('count','condition')]>10000].sort_values(by=('mean','condition') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheapsellers = list( ds[ds.sellingprice<1000].seller.value_counts().head(60).index )\n",
    "print(ds[ds.seller.isin( cheapsellers )].groupby(ds.seller).sellingprice.quantile(.25) )\n",
    "ds.groupby(ds.seller).condition.quantile(.25).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93da334",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_va[ta_va<2000].hist(bins=10,figsize = (20,8),alpha=.5);\n",
    "pr[pr<2000].hist(bins=10,figsize = (20,8),alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db785fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[ds.seller=='credit acceptance corp/vrs/southfield'].sellingprice.hist(bins=50,figsize = (20,8),alpha=0.5);\n",
    "ds[ds.seller.str[:12]=='purple heart'].sellingprice.hist(bins=50,figsize = (20,8),alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[ds['abbr_power']=='PURPLE'].pr.quantile([.1,.25,.5,.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[ds['abbr_power']=='QUALITY'].pr.quantile([.1,.25,.5,.75,.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c16f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
